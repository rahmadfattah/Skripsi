{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c940af-3a47-4a73-bec6-948880dcad64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538557 149599 0\n",
      "Training 538557 0.7200008021443993\n",
      "Validation 149599 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "data_dir = 'Dataset/GAN/BigGan/train'\n",
    "# Define transforms for the training and validation sets\n",
    "data_transforms ={\n",
    "    \"train_transforms\": transforms.Compose([transforms.RandomRotation(30),\n",
    "                                           transforms.RandomResizedCrop(299), \n",
    "                                           transforms.RandomHorizontalFlip(), \n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                                [0.229, 0.224, 0.225])]),\n",
    "   \"valid_transforms\": transforms.Compose([transforms.Resize(300),\n",
    "                                           transforms.CenterCrop(299),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                [0.229, 0.224, 0.225])]), \n",
    "    \"test_transforms\": transforms.Compose([transforms.Resize(300),\n",
    "                                           transforms.CenterCrop(299),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                [0.229, 0.224, 0.225])])\n",
    "}\n",
    "import numpy as np\n",
    "\n",
    "# Set the split ratios for training, validation, and test data\n",
    "train_data_ratio = 0.8\n",
    "valid_data_ratio = 0.2\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"train_transforms\"])\n",
    "valid_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"valid_transforms\"])\n",
    "\n",
    "# Obtain training indices that will be used for validation and test\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "\n",
    "# Calculate the number of samples for training, validation, and test sets\n",
    "train_count = int(train_data_ratio * num_train)\n",
    "valid_count = int(valid_data_ratio * num_train)\n",
    "test_count = num_train - train_count - valid_count\n",
    "\n",
    "# Split the indices into training, validation, and test sets\n",
    "train_idx = indices[:train_count]\n",
    "valid_idx = indices[train_count:train_count + valid_count]\n",
    "test_idx = indices[train_count + valid_count:]\n",
    "\n",
    "# Randomly remove 10% of samples from the training set\n",
    "remove_count = int(0.1 * train_count)\n",
    "np.random.shuffle(train_idx)\n",
    "train_idx = train_idx[:-remove_count]\n",
    "\n",
    "# Print the lengths of training, validation, and test sets\n",
    "print(len(train_idx), len(valid_idx), len(test_idx))\n",
    "\n",
    "# Print the percentage of total data each set represents\n",
    "print(\"Training\", len(train_idx), np.sum(len(train_idx) / num_train))\n",
    "print(\"Validation\", valid_count, np.sum(len(valid_idx) / num_train))\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "# trainloader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True,num_workers=100)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size = 16, shuffle = True,num_workers=100)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size = 32, sampler = valid_sampler)\n",
    "classes=['ai', 'nature']\n",
    "model_transfer = models.resnet50(pretrained=False)\n",
    "\n",
    "# Check if GPU is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()\n",
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad=True\n",
    "n_inputs = model_transfer.fc.in_features #refer to the fully connected layer only\n",
    "\n",
    "# Add last linear layer (n_inputs -> 4 classes). In this case the ouput is 4 classes\n",
    "# New layer automatically has requires_grad = True\n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "\n",
    "model_transfer.fc = last_layer\n",
    "\n",
    "# If GPU is available, move the model to GPU\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()\n",
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "optimizer_transfer = optim.SGD(model_transfer.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6446a51-2a4a-4312-b8d8-8fedc265edcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "\n",
    "classes = ['ai','nature']\n",
    "\n",
    "model1 = models.resnet50(pretrained=True)\n",
    "n_inputs = model1.fc.in_features \n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "model1.fc = last_layer\n",
    "model1.load_state_dict(torch.load('Model/VQDM_Resnet50.pt'))\n",
    "\n",
    "model2 = models.resnet50(pretrained=True)\n",
    "n_inputs = model2.fc.in_features \n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "model2.fc = last_layer\n",
    "model2.load_state_dict(torch.load('Model/GLIDE_Resnet50.pt'))\n",
    "\n",
    "model3 = models.resnet50(pretrained=True)\n",
    "n_inputs = model3.fc.in_features \n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "model3.fc = last_layer\n",
    "model3.load_state_dict(torch.load('Model/GAN_Resnet50.pt'))\n",
    "\n",
    "model4 = models.resnet50(pretrained=True)\n",
    "n_inputs = model3.fc.in_features \n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "model4.fc = last_layer\n",
    "model4.load_state_dict(torch.load('Model/SDM_Resnet50.pt'))\n",
    "\n",
    "model5 = models.resnet50(pretrained=True)\n",
    "n_inputs = model5.fc.in_features \n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "model5.fc = last_layer\n",
    "model5.load_state_dict(torch.load('Midjourney_Resnet50.pt'))\n",
    "\n",
    "modelX = models.resnet50(pretrained=True)\n",
    "n_inputs = model3.fc.in_features \n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "modelX.fc = last_layer\n",
    "modelX.load_state_dict(torch.load('Model/FineTuning40%Only.pt'))\n",
    "\n",
    "# modelZ = models.resnet50()\n",
    "# n_inputs = modelZ.fc.in_features \n",
    "# dropout_rate = 0.5  # You can adjust this value\n",
    "# dropout_layer = nn.Dropout(p=dropout_rate)\n",
    "# # Modify the fully connected layer to include the dropout layer\n",
    "# last_layer_with_dropout = nn.Sequential(\n",
    "#     dropout_layer,\n",
    "#     nn.Linear(n_inputs, len(classes))\n",
    "# )\n",
    "# # Replace the original fully connected layer with the modified one\n",
    "# modelZ.fc = last_layer_with_dropout\n",
    "# modelZ.load_state_dict(torch.load('FineTuning10%Only.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7f3488-7939-4b7b-b2dc-32cc54ea52cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN Testing Result : \n",
      "Test Loss: 0.698414\n",
      "\n",
      "Overall Test Accuracy: 48.942% (5873.0/12000.0)\n",
      "Accuracy for class ai: 22.633% (1358/6000)\n",
      "Accuracy for class nature: 75.250% (4515/6000)\n",
      "Execution Time: 16.65420699119568 seconds\n",
      "\n",
      " GLIDE Testing Result : \n",
      "Test Loss: 0.706561\n",
      "\n",
      "Overall Test Accuracy: 48.892% (5867.0/12000.0)\n",
      "Accuracy for class ai: 21.850% (1311/6000)\n",
      "Accuracy for class nature: 75.933% (4556/6000)\n",
      "Execution Time: 17.53581953048706 seconds\n",
      "\n",
      " VQDM Testing Result : \n",
      "Test Loss: 0.679758\n",
      "\n",
      "Overall Test Accuracy: 56.067% (6728.0/12000.0)\n",
      "Accuracy for class ai: 35.950% (2157/6000)\n",
      "Accuracy for class nature: 76.183% (4571/6000)\n",
      "Execution Time: 18.392539739608765 seconds\n",
      "\n",
      " SDM Testing Result : \n",
      "Test Loss: 0.739727\n",
      "\n",
      "Overall Test Accuracy: 49.825% (9965.0/20000.0)\n",
      "Accuracy for class ai: 0.160% (16/10000)\n",
      "Accuracy for class nature: 99.490% (9949/10000)\n",
      "Execution Time: 26.437470197677612 seconds\n",
      "\n",
      " Midjourney Testing Result : \n",
      "Test Loss: 0.709753\n",
      "\n",
      "Overall Test Accuracy: 48.658% (5839.0/12000.0)\n",
      "Accuracy for class ai: 20.883% (1253/6000)\n",
      "Accuracy for class nature: 76.433% (4586/6000)\n",
      "Execution Time: 67.17779016494751 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def test(loaders, model1, criterion, use_cuda):\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    # monitor per-class accuracy\n",
    "    class_correct = np.zeros(len(loaders['test'].dataset.classes))\n",
    "    class_total = np.zeros(len(loaders['test'].dataset.classes))\n",
    "\n",
    "    model1.eval()  # set model into evaluation/testing mode\n",
    "    start_time = time.time()\n",
    "    # Iterating over test data\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        model1 = model1.to(data.device)\n",
    "\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model1(data)\n",
    "\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # update average test loss\n",
    "        test_loss += ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "\n",
    "        # compare predictions to ground truth\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        total += data.size(0)\n",
    "\n",
    "        # update per-class counts\n",
    "        for i in range(len(loaders['test'].dataset.classes)):\n",
    "            class_correct[i] += pred[target == i].eq(target[target == i].data.view_as(pred[target == i])).sum().item()\n",
    "            class_total[i] += (target == i).sum().item()\n",
    "\n",
    "    # Print test loss, total accuracy, and accuracy for each class\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "    print('Overall Test Accuracy: {:.3f}% ({}/{})'.format(100. * correct / total, correct, total))\n",
    "\n",
    "    for i, class_name in enumerate(loaders['test'].dataset.classes):\n",
    "        class_acc = 100. * class_correct[i] / class_total[i] if class_total[i] != 0 else 0\n",
    "        print('Accuracy for class {}: {:.3f}% ({}/{})'.format(class_name, class_acc, int(class_correct[i]), int(class_total[i])))\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "    print(f'Execution Time: {execution_time} seconds')\n",
    "\n",
    "print('GAN Testing Result : ') \n",
    "test(loaders_transfer1, model5, criterion_transfer, use_cuda)\n",
    "print('\\n GLIDE Testing Result : ') \n",
    "test(loaders_transfer2, model5, criterion_transfer, use_cuda)\n",
    "print('\\n VQDM Testing Result : ') \n",
    "test(loaders_transfer3, model5, criterion_transfer, use_cuda)\n",
    "print('\\n SDM Testing Result : ') \n",
    "test(loaders_transfer4, model5, criterion_transfer, use_cuda)\n",
    "print('\\n Midjourney Testing Result : ') \n",
    "test(loaders_transfer5, model5, criterion_transfer, use_cuda)\n",
    "\n",
    "# print('GAN Testing Result : ') \n",
    "# test(loaders_transfer1, dynamic_ensemble_model, criterion_transfer, use_cuda)\n",
    "# print('\\nGLIDE Testing Result : ') \n",
    "# test(loaders_transfer2, dynamic_ensemble_model, criterion_transfer, use_cuda)\n",
    "# print('\\nVQDM Testing Result : ') \n",
    "# test(loaders_transfer3, dynamic_ensemble_model, criterion_transfer, use_cuda)\n",
    "# print('\\nSDM Testing Result : ') \n",
    "# test(loaders_transfer4, dynamic_ensemble_model, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76f52813-e20c-492b-bb8b-46149fc5b05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN Testing:\n",
      "Test 12000\n",
      "GLIDE Testing:\n",
      "Test 12000\n",
      "VQDM Testing:\n",
      "Test 12000\n",
      "SDM Testing:\n",
      "Test 20000\n",
      "Midjourney Testing:\n",
      "Test 12000\n"
     ]
    }
   ],
   "source": [
    "dir_GAN = 'Dataset/GAN/BigGan/val'\n",
    "dir_GLIDE = 'Dataset/GLIDE/val'\n",
    "dir_VQDM = 'Dataset/VQDM/val'\n",
    "dir_SDM = 'Dataset/SD/test'\n",
    "dir_Midjourney = 'Dataset/MidjourneyZip/Midjourney/val'\n",
    "\n",
    "\n",
    "test_GAN = datasets.ImageFolder(dir_GAN, transform=data_transforms[\"test_transforms\"])\n",
    "test_GLIDE = datasets.ImageFolder(dir_GLIDE, transform=data_transforms[\"test_transforms\"])\n",
    "test_VQDM = datasets.ImageFolder(dir_VQDM, transform=data_transforms[\"test_transforms\"])\n",
    "test_SDM = datasets.ImageFolder(dir_SDM, transform=data_transforms[\"test_transforms\"])\n",
    "test_Midjourney = datasets.ImageFolder(dir_Midjourney, transform=data_transforms[\"test_transforms\"])\n",
    "\n",
    "print('GAN Testing:')\n",
    "GAN_count = len(test_GAN)\n",
    "GAN_idx = indices[:GAN_count]\n",
    "print(\"Test\", GAN_count)\n",
    "test_sampler = SubsetRandomSampler(GAN_idx)\n",
    "testloaderGAN = torch.utils.data.DataLoader(test_GAN, batch_size = 16, sampler = test_sampler,num_workers=4)\n",
    "loaders_transfer1 = {'test': testloaderGAN}   \n",
    "\n",
    "print('GLIDE Testing:')\n",
    "GLIDE_count = len(test_GLIDE)\n",
    "GLIDE_idx = indices[:GLIDE_count]\n",
    "print(\"Test\", GLIDE_count)\n",
    "test_sampler = SubsetRandomSampler(GLIDE_idx)\n",
    "testloaderGLIDE = torch.utils.data.DataLoader(test_GLIDE, batch_size = 16, sampler = test_sampler,num_workers=4)\n",
    "loaders_transfer2 = {'test': testloaderGLIDE}  \n",
    "\n",
    "print('VQDM Testing:')\n",
    "VQDM_count = len(test_VQDM)\n",
    "VQDM_idx = indices[:VQDM_count]\n",
    "print(\"Test\", VQDM_count)\n",
    "test_sampler = SubsetRandomSampler(VQDM_idx)\n",
    "testloaderVQDM = torch.utils.data.DataLoader(test_VQDM, batch_size = 16, sampler = test_sampler,num_workers=4)\n",
    "loaders_transfer3 = {'test': testloaderVQDM}  \n",
    "\n",
    "print('SDM Testing:')\n",
    "SDM_count = len(test_SDM)\n",
    "SDM_idx = indices[:SDM_count]\n",
    "print(\"Test\", SDM_count)\n",
    "test_sampler = SubsetRandomSampler(SDM_idx)\n",
    "testloaderSDM = torch.utils.data.DataLoader(test_SDM, batch_size = 16, sampler = test_sampler,num_workers=4)\n",
    "loaders_transfer4 = {'test': testloaderSDM}  \n",
    "\n",
    "print('Midjourney Testing:')\n",
    "Midjourney_count = len(test_Midjourney)\n",
    "Midjourney_idx = indices[:Midjourney_count]\n",
    "print(\"Test\", Midjourney_count)\n",
    "test_sampler = SubsetRandomSampler(Midjourney_idx)\n",
    "testloaderMidjourney = torch.utils.data.DataLoader(test_Midjourney, batch_size = 16, sampler = test_sampler,num_workers=4)\n",
    "loaders_transfer5 = {'test': testloaderMidjourney}  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ed29b29-d195-4506-9a76-d716c63c6244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set models to evaluation mode\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "model4.eval()\n",
    "\n",
    "# Initialize weights equally\n",
    "w1, w2, w3, w4 = 0.25, 0.25, 0.25, 0.25\n",
    "\n",
    "# Define a new class for the ensemble\n",
    "class DynamicWeightedEnsemble(nn.Module):\n",
    "    def __init__(self, model1, model2, model3, model4):\n",
    "        super(DynamicWeightedEnsemble, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        self.model4 = model4\n",
    "\n",
    "        # Convert weights to parameters so they can be updated during optimization\n",
    "        self.weights = nn.Parameter(torch.tensor([w1, w2, w3, w4], requires_grad=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.model1(x)\n",
    "        out2 = self.model2(x)\n",
    "        out3 = self.model3(x)\n",
    "        out4 = self.model4(x)\n",
    "\n",
    "        # Combine the outputs using dynamic weights\n",
    "        weights_softmax = F.softmax(self.weights, dim=0)\n",
    "        # print(\"Softmax Weights:\", weights_softmax)\n",
    "        # out = weights_softmax[0] * out1 + weights_softmax[1] * out2 + weights_softmax[2] * out3 + weights_softmax[3] * out4\n",
    "        out = 0.3180 * out1 + 0.1681 * out2 + 0.1695 * out3 + 0.3445 * out4\n",
    "        return out\n",
    "\n",
    "# Create an instance of the dynamic weighted ensemble model\n",
    "dynamic_ensemble_model = DynamicWeightedEnsemble(model1, model2, model3, model4)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dynamic_ensemble_model.to(device)\n",
    "dynamic_ensemble_model.load_state_dict(torch.load('Model/GATING.pt'))\n",
    "# dynamic_ensemble_model.load_state_dict(torch.load('Model/GATING.pt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad96bb-91d8-4aaf-a1fd-4b8e3da33fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
